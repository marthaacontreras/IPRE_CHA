---
title: "Master CHA1-3 Combined"
date: "2024-06-20"
output:
  html_document:
    theme: cerulean
    toc: yes
    toc_float:
      collapsed: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
This setup is commonly used at the beginning of an R Markdown document to configure global settings for code chunks, ensuring consistent behavior throughout the document.

```{r message=FALSE, warning=FALSE}
install.packages(c("rvest", "httr", "stringr"))
install.packages("RSelenium")
install.packages("webdriver")
install.packages("chromedriver")

library(tidyverse)
library(rio)
library(janitor)
library(dplyr)
library(rvest) 
library(httr) 
library(stringr)
library(RSelenium)

```

```{r}
CHA_2020_4 <- rio::import("https://github.com/wellsdata/DJNF_Merrill/raw/main/data/CHA_Data_24_053R.xlsx", sheet = "2020Q4") %>% 
  mutate(quarter="2020Q4") %>% 
  clean_names()

CHA_2021_1 <- rio::import("https://github.com/wellsdata/DJNF_Merrill/raw/main/data/CHA_Data_24_053R.xlsx", sheet = "2021Q1") %>% 
  mutate(quarter="2021Q1") %>% 
  clean_names()

CHA_2021_2 <- rio::import("https://github.com/wellsdata/DJNF_Merrill/raw/main/data/CHA_Data_24_053R.xlsx", sheet = "2021Q2") %>% 
  mutate(quarter="2021Q2") %>% 
  clean_names()

CHA_2021_3 <- rio::import("https://github.com/wellsdata/DJNF_Merrill/raw/main/data/CHA_Data_24_053R.xlsx", sheet = "2021Q3") %>% 
  mutate(quarter="2021Q3") %>% 
  clean_names() %>% 
  rename(vendor_id = vendor_i)

CHA_2021_4 <- rio::import("https://github.com/wellsdata/DJNF_Merrill/raw/main/data/CHA_Data_24_053R.xlsx", sheet = "2021Q4") %>% 
  mutate(quarter="2021Q4") %>% 
  clean_names() %>% 
  rename(vendor_id = vendor_i)

CHA_2022_1 <- rio::import("https://github.com/wellsdata/DJNF_Merrill/raw/main/data/CHA_Data_24_053R.xlsx", sheet = "2022Q1") %>% 
  mutate(quarter="2022Q1") %>% 
  clean_names() %>% 
  rename(vendor_id = vendor_i)

CHA_2022_2 <- rio::import("https://github.com/wellsdata/DJNF_Merrill/raw/main/data/CHA_Data_24_053R.xlsx", sheet = "2022Q2") %>% 
  mutate(quarter="2022Q2") %>% 
  clean_names() %>% 
  rename(vendor_id = vendor_i)

CHA_2022_3 <- rio::import("https://github.com/wellsdata/DJNF_Merrill/raw/main/data/CHA_Data_24_053R.xlsx", sheet = "2022Q3") %>% 
  mutate(quarter="2022Q3") %>% 
  clean_names() %>% 
  rename(vendor_id = vendor_i)

CHA_2022_4 <- rio::import("https://github.com/wellsdata/DJNF_Merrill/raw/main/data/CHA_Data_24_053R.xlsx", sheet = "2022Q4") %>% 
  mutate(quarter="2022Q4") %>% 
  clean_names() %>% 
  rename(vendor_id = vendor_i)

CHA_2023_1 <- rio::import("https://github.com/wellsdata/DJNF_Merrill/raw/main/data/CHA_Data_24_053R.xlsx", sheet = "2023Q1") %>% 
  mutate(quarter="2023Q1") %>% 
  clean_names() %>% 
  rename(vendor_id = vendor_i)

CHA_2023_2 <- rio::import("https://github.com/wellsdata/DJNF_Merrill/raw/main/data/CHA_Data_24_053R.xlsx", sheet = "2023Q2") %>% 
  mutate(quarter="2023Q2") %>% 
  clean_names() %>% 
  rename(vendor_id = vendor_i)

CHA_2023_3 <- rio::import("https://github.com/wellsdata/DJNF_Merrill/raw/main/data/CHA_Data_24_053R.xlsx", sheet = "2023Q3") %>% 
  mutate(quarter="2023Q3") %>% 
  clean_names() %>% 
  rename(vendor_id = vendor_i)

CHA_2023_4 <- rio::import("https://github.com/wellsdata/DJNF_Merrill/raw/main/data/CHA_Data_24_053R.xlsx", sheet = "2023Q4") %>% 
  mutate(quarter="2023Q4") %>% 
  clean_names() 
```

```{r}

CHA1 <- rbind(CHA_2020_4, CHA_2021_1, CHA_2021_2, CHA_2021_3, CHA_2021_4, CHA_2022_1, CHA_2022_2, CHA_2022_3, CHA_2022_4, CHA_2023_1, CHA_2023_2, CHA_2023_3, CHA_2023_4)

write.csv(CHA1,"CHA1.csv")
```

```{r}

CHA2_2019 <- import("CHA2(Jan2019-April2024).xlsx", sheet = "2019") %>% 
  mutate(year="2019") %>% 
  clean_names()

CHA2_2020 <- import("CHA2(Jan2019-April2024).xlsx", sheet = "2020") %>% 
  mutate(year="2020") %>% 
  clean_names()

CHA2_2021 <- import("CHA2(Jan2019-April2024).xlsx", sheet = "2021") %>% 
  mutate(year="2021") %>% 
  clean_names()

CHA2_2022 <- import("CHA2(Jan2019-April2024).xlsx", sheet = "2022") %>% 
  mutate(year="2022") %>% 
  clean_names()

CHA2_2023 <- import("CHA2(Jan2019-April2024).xlsx", sheet = "2023") %>% 
  mutate(year="2023") %>% 
  clean_names()

CHA2_2024 <- import("CHA2(Jan2019-April2024).xlsx", sheet = "2024 April") %>% 
  mutate(year="2024") %>% 
  clean_names()

CHA2 <- rbind(CHA2_2019, CHA2_2020, CHA2_2021, CHA2_2022, CHA2_2023, CHA2_2024)

CHA2$vendor_zip <- as.numeric(CHA2$vendor_zip)
CHA2$payment_month_number <- as.numeric(CHA2$payment_month_number)
CHA2$bedroom_size <- as.numeric(CHA2$bedroom_size)

write.csv(CHA2,"CHA2.csv")

colnames(CHA2)

summary(CHA2$vendor_address_line_1)

CHA2 %>% 
  count(vendor_address_line_1) %>% 
  arrange(desc(n)) %>% 
  head(10) 

#because there are multiple entries per month (grrrr), going to have to go with total payment amount to find any valuable data analysis 

sum(CHA2$payment_amount, na.rm = TRUE)
# [1] 2,867,739,566
mean(CHA2$payment_amount, na.rm = TRUE)
# 845.3352

vendors <- CHA2 %>% 
  select(vendor_name, vendor_address_line_1, payment_amount, year, zip) %>% 
  group_by(vendor_address_line_1) %>% 
  summarize(
    # vendor_name,
    # year,
    # zip,
    Total_Payment = sum(payment_amount, na.rm=TRUE), 
    Mean_Payment = mean(payment_amount, na.rm=TRUE),
    
    ) %>%  
  arrange(desc(Total_Payment))

#how much money each vendor receives from the CHA per year (yearly breakdown to find patterns over time)
vendors_year <- CHA2 %>% 
  select(vendor_name, vendor_address_line_1, payment_amount, year, zip) %>% 
  group_by(vendor_address_line_1, year) %>% 
  summarize(
    # vendor_name,
    # year,
    # zip,
    Total_Payment = sum(payment_amount, na.rm=TRUE), 
    Mean_Payment = mean(payment_amount, na.rm=TRUE),
    
    ) %>%  
  arrange(desc(Total_Payment))

# leases_per_owner <- CHA2 %>% 
#   count(vendor_name) %>% 
#   arrange(n) 
 

```
Zipcodes extracted from CHA2 dataset
```{r}
# zip_list <- CHA2 %>% 
#   select(year, zip)%>% 
#   group_by(zip) 
# 
# CHA2 %>% 
#   count(zip) %>% 
#   arrange(n)

zip_list_per_year <- CHA2 %>% 
  mutate(zip = substr(zip, 1, 6)) %>%  # Extract first 6 digits of the zip code
  group_by(year, zip) %>%              # Group by year and the modified zip code
  summarise(count = n())               # Count occurrences

zip_list <- CHA2 %>% 
  mutate(zip = substr(zip, 1, 5)) %>%  # Extract first 6 digits of the zip code
  group_by(zip) %>%              # Group by year and the modified zip code
  summarise(count = n())

```
Census Tract HUV zipcode data 
```{r}
#web scraping for all data sets with zip codes 

# # List of 86 ZIP codes from CHA2
# zip_codes <- c("60014", "60026", "60050", "60077", "60085", "60098", "60104",
#                "60155", "60201", "60302", "60409", "60411", "60419", "60422",
#                "60425", "60426", "60428", "60429", "60432", "60438", "60445",
#                "60458", "60465", "60471", "60473", "60478", "60601", "60602",
#                "60603", "60605", "60606", "60607", "60608", "60609", "60610",
#                "60611", "60612", "60613", "60614", "60615", "60616", "60617",
#                "60618", "60619", "60620", "60621", "60622", "60623", "60624",
#                "60625", "60626", "60628", "60629", "60630", "60631", "60632",
#                "60633", "60634", "60636", "60637", "60638", "60639", "60640",
#                "60641", "60642", "60643", "60644", "60645", "60646", "60647",
#                "60649", "60651", "60652", "60653", "60654", "60655", "60656",
#                "60657", "60659", "60660", "60661", "60707", "60803", "60805",
#                "60827")
#The Amount calulated per zip code is skewed because uneven amount of months per property and even entries per month (going to need to use CHA1 for zipcode breakdown per amount but will limit the time frame for data)

#using R Selium 
 
#MASSIVE ATTEMPT TO USE WEB SCRAPING AND FETCHING CODE BUT HIT TOO MANY ROAD BLOCKS. IGNORE ALL OF CODE BELOW. USELESS
# 
# #Start the Selenium server
# remDr <- remoteDriver(remoteServerAddr = "localhost",
#                       port = 4444,
#                       browserName = "chrome")
# 
# # Navigate to the webpage
# remDr$navigate("https://www.huduser.gov/portal/datasets/assthsg.html#query_2009-2023")
# 
# # Wait for the page to load (you can adjust the timeout as needed)
# Sys.sleep(5)
# 
# # Get the HTML content
# html <- remDr$getPageSource()[[1]]
# 
# # Parse the HTML content using a package like rvest
# library(rvest)
# html_doc <- read_html(html)
# 
# 
# # Select the 2019 option from the select_year dropdown
# remDr$findElement(using = "xpath", value = "//select[@id='Year']/option[@value='2019']")$click()
# 
# # Select the "Zipcode" option from the summary_level dropdown
# remDr$findElement(using = "xpath", value = "//select[@id='summary_level']/option[@value='zipcode||11']")$click()
#  
# #Insert a zip code value
# remDr$findElement(using = "xpath", value = "//input[@id='second_level_zipcode']")$sendKeysToElement(list("60014"))
# 
# # Select the Housing Choice Vouchers program
# remDr$findElement(using = "xpath", value = "//select[@id='program']/option[@value='program_HCV']")$click()
# 
# # Select a variable
# remDr$findElement(using = "xpath", value = "//select[@id='variable']/option[@value='all']")$click()
#  
# # Click the "Get Results" button
# remDr$findElement(using = "xpath", value = "//input[@value='Get Results']")$click()
# 
# # Wait for the data to load
# Sys.sleep(2)
# 
# # Extract the data
# data <- remDr$findElement(using = "xpath", value = "//div[@id='datafromdb']")$getText()
# 
# # Close the Selenium server
# remDr$close()
# driver[["server"]]$stop()
# 
# # Process the data
# data <- gsub("\r\n", "", data)
# data <- strsplit(data, "\n")[[1]]
# data <- data[-1]  # Remove the header
# 
# # Convert the data to a data frame
# data_df <- data.frame(t(data))
# 
# # Print the data frame
# print(data_df)
# 
# ```
# 
# ```{r}
# 
# #Step 1: Navigate to the web page and extract elements
# # Get the webpage
# url <- "https://www.huduser.gov/portal/datasets/assthsg.html#query_2009-2023" 
# webpage <- read_html(url)
# 
# # Extract the elements you need
# # For example, to get the values for the year select box:
# year_options <- webpage %>% 
#   html_nodes("2019", "2020", "2021", "2022_2020census", "2023") %>% #inputting the VALUE of the search bar options looking at the html page
#   html_text()
# 
# # Extract the elements for the summary level:
# summary_level_options <- webpage %>% 
#   html_nodes("Select a Year", "Select a Summary Level", "Select a Program Level", "Select a Variable Level") %>% 
#   html_text()
# 
# #Step 2: Formulate and Submit Your Search Query
# search_query <- list(
#   year = "2019", # Replace with your desired year
#   zip_code = "60014" # Replace with your desired zip code
# )
# 
# # You might need to adjust the names of the variables in the query list based on the HTML structure of the search page.
# # See if the webpage has an input for the zip code.
# zip_code_input <- webpage %>% html_nodes("input[name='zipcode||11']") 
# 
# # You might need to adjust the name "zip_code" in the query to match what the page expects based on the HTML structure of the page.
# 
# #Step3: Submit the Search Query and Retrieve the Results
# # Submit the search query using POST request:
# response <- POST(url, body = search_query)
# 
# # Check if the request was successful
# if (response$status_code == 200) {
#   # Extract the HTML content of the results page
#   results_page <- content(response, as = "text") 
#   # Parse the results page
#   results_html <- read_html(results_page)
# 
#   # Extract the data from the results page
#   # For example, to extract table data:
#   results_table <- results_html %>%
#     html_nodes("table") %>%
#     html_table()
# 
#   # Process and save the results data
#   # ...
# } else {
#   print("Error submitting search query.")
# }


